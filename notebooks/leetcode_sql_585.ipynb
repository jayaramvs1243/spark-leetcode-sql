{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5245fd8-80e3-49e1-ab4e-cb75b6c63fb1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### LeetCode - SQL - #585\n",
    "\n",
    "Refer [585. Investments in 2016](https://leetcode.com/problems/investments-in-2016/description/)\n",
    "\n",
    "Write a solution to report the sum of all total investment values in 2016  `tiv_2016`, for all policyholders who:\n",
    "\n",
    "-   have the same  `tiv_2015`  value as one or more other policyholders, and\n",
    "-   are not located in the same city as any other policyholder (i.e., the (`lat, lon`) attribute pairs must be unique).\n",
    "\n",
    "Round  `tiv_2016`  to  **two decimal places**."
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_insurance = [[1, 10, 5, 10, 10], [2, 20, 20, 20, 20], [3, 10, 30, 20, 20], [4, 10, 40, 40, 40]]\n",
    "columns_insurance = ['pid', 'tiv_2015', 'tiv_2016', 'lat', 'lon']\n",
    "schema_insurance = {'pid':'Int64', 'tiv_2015':'Float64', 'tiv_2016':'Float64', 'lat':'Float64', 'lon':'Float64'}"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "pandas_df_insurance = pandas.DataFrame(data=data_insurance, columns=columns_insurance).astype(schema_insurance)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark_context = SparkSession.builder.master(\"local[1]\").appName(\"LeetCode SQL\").getOrCreate()\n",
    "\n",
    "# Spark DataFrame using Pandas DataFrame\n",
    "df_insurance = spark_context.createDataFrame(pandas_df_insurance)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Using Window Fuctions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "window_spec_tiv_2015 = Window.partitionBy(df_insurance.tiv_2015)\n",
    "window_spec_lat_lan = Window.partitionBy(df_insurance.lat, df_insurance.lon)\n",
    "\n",
    "df_insurance_summary \\\n",
    "    = df_insurance \\\n",
    "        .withColumn(\"tiv_2015_count\", F.count(\"*\").over(window_spec_tiv_2015)) \\\n",
    "        .withColumn(\"lat_lan_count\", F.count(\"*\").over(window_spec_lat_lan))\n",
    "df_insurance_summary.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_insurance_summary \\\n",
    "    .filter((df_insurance_summary.tiv_2015_count > 1) & (df_insurance_summary.lat_lan_count == 1)) \\\n",
    "    .select(F.round(F.sum(df_insurance_summary.tiv_2016), 2).alias(\"tiv_2016\")) \\\n",
    "    .show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Using IN clause"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_insurance_tiv_2015_multiple \\\n",
    "    = df_insurance.groupBy(df_insurance.tiv_2015).count() \\\n",
    "        .filter(F.col(\"count\") > 1) \\\n",
    "        .select(F.col(\"tiv_2015\"))\n",
    "\n",
    "# Convert to Python list\n",
    "list_insurance_tiv_2015_multiple = list(df_insurance_tiv_2015_multiple.toPandas()['tiv_2015'])\n",
    "print(list_insurance_tiv_2015_multiple)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_insurance_lat_lon_unique \\\n",
    "    = df_insurance.groupBy(df_insurance.lat, df_insurance.lon).count() \\\n",
    "        .filter(F.col(\"count\") == 1) \\\n",
    "        .select(F.concat_ws(\"-\", df_insurance.lat, df_insurance.lon).alias(\"lat_lan\"))\n",
    "\n",
    "# Convert to Python list\n",
    "list_insurance_lat_lon_unique = list(df_insurance_lat_lon_unique.toPandas()['lat_lan'])\n",
    "print(list_insurance_lat_lon_unique)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_insurance.show()\n",
    "\n",
    "df_insurance \\\n",
    "    .filter(df_insurance.tiv_2015.isin(list_insurance_tiv_2015_multiple) & F.concat_ws(\"-\", df_insurance.lat, df_insurance.lon).isin(list_insurance_lat_lon_unique)) \\\n",
    "    .select(F.sum(df_insurance.tiv_2016).alias(\"tiv_2016\")) \\\n",
    "    .show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "leetcode_sql_585",
   "widgets": {}
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
