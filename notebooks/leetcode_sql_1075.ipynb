{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#### LeetCode - SQL - #1075\n",
    "\n",
    "Refer [1075. Project Employees I](https://leetcode.com/problems/project-employees-i/description/)\n",
    "\n",
    "Write an SQL query that reports the average experience years of all the employees for each project, rounded to 2 digits.\n",
    "\n",
    "Return the result table in any order."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea19d62eff13a6d2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_project = [[1, 1], [1, 2], [1, 3], [2, 1], [2, 4]]\n",
    "columns_project = ['project_id', 'employee_id']\n",
    "schema_project = {'project_id':'Int64', 'employee_id':'Int64'}\n",
    "\n",
    "data_employee = [[1, 'Khaled', 3], [2, 'Ali', 2], [3, 'John', 1], [4, 'Doe', 2]]\n",
    "columns_employee = ['employee_id', 'name', 'experience_years']\n",
    "schema_employee = {'employee_id':'Int64', 'name':'object', 'experience_years':'Int64'}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T18:03:28.907853Z",
     "start_time": "2024-03-19T18:03:28.905087Z"
    }
   },
   "id": "208d299dd9cbdbd1",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark_context = SparkSession.builder.appName('LeetCode SQL').getOrCreate()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4be72b4017ceea69",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create Spark Dataframe using Pandas\n",
    "import pandas\n",
    "\n",
    "pandas_df_project = pandas.DataFrame(data=data_project, columns=columns_project).astype(schema_project)\n",
    "pandas_df_employee = pandas.DataFrame(data=data_employee, columns=columns_employee).astype(schema_employee)\n",
    "\n",
    "df_project = spark_context.createDataFrame(pandas_df_project)\n",
    "df_employee = spark_context.createDataFrame(pandas_df_employee)\n",
    "\n",
    "df_project.printSchema()\n",
    "df_employee.printSchema()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71b492785b3de7e6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create Spark Dataframe using PySpark functions - 1\n",
    "schema_project = 'project_id integer, employee_id integer'\n",
    "schema_employee = 'employee_id integer, name string, experience_years integer'\n",
    "\n",
    "df_project = spark_context.createDataFrame(data=data_project, schema=schema_project)\n",
    "df_employee = spark_context.createDataFrame(data=data_employee, schema=schema_employee)\n",
    "\n",
    "df_project.printSchema()\n",
    "df_employee.printSchema()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6590c63affa6e924",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create Spark Dataframe using PySpark functions - 2\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "schema_project = StructType([\n",
    "    StructField('project_id', IntegerType(), False),\n",
    "    StructField('employee_id', IntegerType(), False)\n",
    "])\n",
    "df_project = spark_context.createDataFrame(data=data_project, schema=schema_project)\n",
    "df_project.printSchema()\n",
    "\n",
    "schema_employee = StructType([\n",
    "    StructField('employee_id', IntegerType(), False),\n",
    "    StructField('name', StringType(), True),\n",
    "    StructField('experience_years', IntegerType(), True)\n",
    "])\n",
    "df_employee = spark_context.createDataFrame(data=data_employee, schema=schema_employee)\n",
    "df_employee.printSchema()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f79a8e902afeceb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+\n",
      "|project_id|average_years|\n",
      "+----------+-------------+\n",
      "|         1|          2.0|\n",
      "|         2|          2.5|\n",
      "+----------+-------------+\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "df_project_employee \\\n",
    "    = df_project.join(\n",
    "        df_employee,\n",
    "        df_project.employee_id == df_employee.employee_id,\n",
    "        'inner'\n",
    "    ).select(\n",
    "        df_project.project_id,\n",
    "        df_employee.employee_id,\n",
    "        df_employee.experience_years\n",
    "    )\n",
    "\n",
    "df_project_employee.groupBy(df_project_employee.project_id).agg(\n",
    "    F.round(F.avg(df_project_employee.experience_years), 2).alias('average_years')\n",
    ").show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T18:16:43.836448Z",
     "start_time": "2024-03-19T18:16:43.451971Z"
    }
   },
   "id": "c446612bbda8b6f1",
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
