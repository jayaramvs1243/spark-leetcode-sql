{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#### LeetCode - SQL - #626\n",
    "\n",
    "Refer [626. Exchange Seats](https://leetcode.com/problems/exchange-seats/description/)\n",
    "\n",
    "Write a solution to swap the seat id of every two consecutive students. If the number of students is odd, the id of the last student is not swapped.\n",
    "\n",
    "Return the result table ordered by  `id`  **in ascending order**."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6cd4b5f02fb9b3c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_seat = [[1, 'Abbot'], [2, 'Doris'], [3, 'Emerson'], [4, 'Green'], [5, 'Jeames']]\n",
    "columns_seat = ['id', 'student']\n",
    "schema_seat = {'id':'Int64', 'student':'object'}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3a03d93d77116aa",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark_context = SparkSession.builder.appName('LeetCode SQL').getOrCreate()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b3b19d080c19344",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create Spark Dataframe using Pandas\n",
    "import pandas\n",
    "\n",
    "pandas_df_seat = pandas.DataFrame(data=data_seat, columns=columns_seat).astype(schema_seat)\n",
    "\n",
    "df_seat = spark_context.createDataFrame(pandas_df_seat)\n",
    "df_seat.schema\n",
    "df_seat.show(5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8fed5198617eef7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create Spark Dataframe using PySpark functions - 1\n",
    "schema_seat = 'id integer, student string'\n",
    "\n",
    "df_seat = spark_context.createDataFrame(data=data_seat, schema=schema_seat)\n",
    "df_seat.schema\n",
    "df_seat.show(5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d17c5768e1755a14",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create Spark Dataframe using PySpark functions - 2\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "schema_seat = StructType([\n",
    "    StructField('id', IntegerType(), False),\n",
    "    StructField('student', StringType(), True)\n",
    "])\n",
    "\n",
    "df_seat = spark_context.createDataFrame(data=data_seat, schema=schema_seat)\n",
    "df_seat.schema\n",
    "df_seat.show(5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2664f384baa19831",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "window_spec = Window.orderBy(df_seat.id.asc())\n",
    "\n",
    "df_seat \\\n",
    "    .select(\n",
    "        df_seat.id.alias('id'),\n",
    "        F.when(\n",
    "            ((df_seat.id % 2) == 0),\n",
    "            F.lag(df_seat.student).over(window_spec)\n",
    "        ).otherwise(\n",
    "            F.when(\n",
    "                F.lead(df_seat.student).over(window_spec).isNotNull(),\n",
    "                F.lead(df_seat.student).over(window_spec)\n",
    "            ).otherwise(\n",
    "                df_seat.student\n",
    "            )\n",
    "        ).alias('student')\n",
    "    ).show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e50124c250cdcc96",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
