{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6384bea3-e5a6-4c45-91c6-4b5c6c1bf660",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### LeetCode - SQL - #184\n",
    "\n",
    "Refer [184. Department Highest Salary](https://leetcode.com/problems/department-highest-salary/description/)\n",
    "\n",
    "Write a solution to find employees who have the highest salary in each of the departments.\n",
    "\n",
    "Return the result table in  **any order**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "851604bc-0154-4cdf-aa22-79609d550fcb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "employee_data = [[1, 'Joe', 70000, 1], [2, 'Jim', 90000, 1], [3, 'Henry', 80000, 2], [4, 'Sam', 60000, 2], [5, 'Max', 90000, 1]]\n",
    "employee_columns = ['id', 'name', 'salary', 'departmentId']\n",
    "employee_schema = {'id':'Int64', 'name':'object', 'salary':'Int64', 'departmentId':'Int64'}\n",
    "\n",
    "department_data = [[1, 'IT'], [2, 'Sales']]\n",
    "department_columns = ['id', 'name']\n",
    "department_schema = {'id':'Int64', 'name':'object'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6629893c-1592-4d2e-a4bc-bd3e923fd221",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "employee_pandas_dataframe = pandas.DataFrame(data=employee_data, columns=employee_columns).astype(employee_schema)\n",
    "department_pandas_dataframe = pandas.DataFrame(data=department_data, columns=department_columns).astype(department_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91b7bfda-2866-4d98-860f-c0a05068f6ba",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- id: long (nullable = true)\n |-- name: string (nullable = true)\n |-- salary: long (nullable = true)\n |-- departmentId: long (nullable = true)\n\n+---+-----+------+------------+\n| id| name|salary|departmentId|\n+---+-----+------+------------+\n|  1|  Joe| 70000|           1|\n|  2|  Jim| 90000|           1|\n|  3|Henry| 80000|           2|\n|  4|  Sam| 60000|           2|\n|  5|  Max| 90000|           1|\n+---+-----+------+------------+\n\nroot\n |-- id: long (nullable = true)\n |-- name: string (nullable = true)\n\n+---+-----+\n| id| name|\n+---+-----+\n|  1|   IT|\n|  2|Sales|\n+---+-----+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark_context = SparkSession.builder.appName(\"LeetCode SQL\").getOrCreate()\n",
    "\n",
    "# Spark DataFrame using Pandas DataFrame\n",
    "employee_dataframe = spark_context.createDataFrame(employee_pandas_dataframe)\n",
    "employee_dataframe.printSchema()\n",
    "employee_dataframe.show(5)\n",
    "\n",
    "department_dataframe = spark_context.createDataFrame(department_pandas_dataframe)\n",
    "department_dataframe.printSchema()\n",
    "department_dataframe.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76c152ab-cc18-4fdd-b30c-135f39cca8f1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------------+\n| name|salary|department_name|\n+-----+------+---------------+\n|  Joe| 70000|             IT|\n|  Jim| 90000|             IT|\n|Henry| 80000|          Sales|\n|  Sam| 60000|          Sales|\n|  Max| 90000|             IT|\n+-----+------+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "joined_dataframe \\\n",
    "    = employee_dataframe \\\n",
    "        .join(department_dataframe, employee_dataframe.departmentId == department_dataframe.id, \"inner\") \\\n",
    "        .select(employee_dataframe.name, employee_dataframe.salary, department_dataframe.name.alias(\"department_name\"))\n",
    "joined_dataframe.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c9232da-4dbe-4fbe-84bb-a00d976e6d85",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------------+----------------------+\n| name|salary|department_name|department_salary_rank|\n+-----+------+---------------+----------------------+\n|  Jim| 90000|             IT|                     1|\n|  Max| 90000|             IT|                     1|\n|  Joe| 70000|             IT|                     2|\n|Henry| 80000|          Sales|                     1|\n|  Sam| 60000|          Sales|                     2|\n+-----+------+---------------+----------------------+\n\n+----------+--------+------+\n|Department|Employee|Salary|\n+----------+--------+------+\n|        IT|     Jim| 90000|\n|        IT|     Max| 90000|\n|     Sales|   Henry| 80000|\n+----------+--------+------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import dense_rank\n",
    "\n",
    "window_spec = Window.partitionBy(joined_dataframe.department_name).orderBy(joined_dataframe.salary.desc())\n",
    "\n",
    "joined_dataframe = joined_dataframe.withColumn(\"department_salary_rank\", dense_rank().over(window_spec))\n",
    "joined_dataframe.show(5)\n",
    "\n",
    "joined_dataframe \\\n",
    "    .filter(joined_dataframe.department_salary_rank == 1) \\\n",
    "    .select(joined_dataframe.department_name.alias(\"Department\"), joined_dataframe.name.alias(\"Employee\"), joined_dataframe.salary.alias(\"Salary\")) \\\n",
    "    .show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "leetcode_sql_184",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
